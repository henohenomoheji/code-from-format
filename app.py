import base64
import json
import logging
import os
import mimetypes
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List

import streamlit as st
from openai import AzureOpenAI, OpenAI

if TYPE_CHECKING:  # pragma: no cover - hints only
    from streamlit.runtime.uploaded_file_manager import UploadedFile


logging.basicConfig(level=logging.INFO)

st.set_page_config(
    page_title="Create Manual From images",
    layout="wide",
    page_icon="ğŸ“˜",
)


DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)


def _create_batch_dir() -> Path:
    """Create (or reuse) a timestamped directory data/YYYYMMDDHHMM/."""
    timestamp = datetime.now().strftime("%Y%m%d%H%M")
    batch_dir = DATA_DIR / timestamp
    batch_dir.mkdir(parents=True, exist_ok=True)
    return batch_dir


def _resolve_mime(file_name: str, provided: str | None) -> str:
    """Return a best-effort mime string for the given file."""
    if provided:
        return provided
    guessed, _ = mimetypes.guess_type(file_name)
    return guessed or "image/png"


def _persist_uploaded_files(files: List["UploadedFile"]) -> Dict[str, Dict[str, str]]:
    """Save uploaded files to disk and store their paths/mime in session state."""
    if not files:
        return {}

    batch_dir = _create_batch_dir()
    saved: Dict[str, Dict[str, str]] = {}

    for file in files:
        safe_name = Path(file.name).name
        destination = batch_dir / safe_name
        destination.write_bytes(file.getvalue())
        file.seek(0)
        saved[file.name] = {
            "path": str(destination),
            "mime": _resolve_mime(file.name, file.type),
        }

    st.session_state["saved_images"] = saved
    st.session_state["current_batch_dir"] = str(batch_dir)
    return saved


def _ensure_saved_images(files: List["UploadedFile"]) -> Dict[str, Dict[str, str]]:
    """Persist files when necessary and return the saved metadata."""
    if not files:
        st.session_state["saved_images"] = {}
        st.session_state["current_batch_dir"] = ""
        return {}

    saved: Dict[str, Dict[str, str]] = st.session_state.get("saved_images", {})
    uploaded_names = {file.name for file in files}
    saved_names = set(saved.keys())
    paths_exist = all(Path(meta["path"]).exists() for meta in saved.values()) if saved else False

    if not saved or uploaded_names != saved_names or not paths_exist:
        return _persist_uploaded_files(files)

    return saved


def _init_state() -> None:
    """Ensure session keys exist."""
    st.session_state.setdefault("ai_responses", {})
    st.session_state.setdefault("ai_manual_response", "")
    st.session_state.setdefault("manual_json", {})
    st.session_state.setdefault("manual_markdown", "")
    st.session_state.setdefault("saved_json_path", "")
    st.session_state.setdefault("raw_texts", {})
    st.session_state.setdefault("saved_images", {})
    st.session_state.setdefault("current_batch_dir", "")


def _build_client(
    provider: str,
    openai_api_key: str,
    openai_model_name: str,
    azure_api_key: str,
    azure_endpoint: str,
    azure_deployment: str,
    azure_api_version: str,
) -> tuple[Any | None, str]:
    """Return an initialized OpenAI/Azure client and target model name."""
    if provider == "OpenAI":
        if not openai_api_key:
            st.error("OpenAI API Key ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return None, ""
        if not openai_model_name.strip():
            st.error("OpenAI ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return None, ""
        return OpenAI(api_key=openai_api_key), openai_model_name.strip()

    if not azure_api_key:
        st.error("Azure OpenAI API Key ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return None, ""
    if not azure_endpoint:
        st.error("Azure OpenAI Endpoint ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return None, ""
    if not azure_deployment:
        st.error("Azure ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return None, ""
    client = AzureOpenAI(
        api_key=azure_api_key,
        azure_endpoint=azure_endpoint,
        api_version=azure_api_version or "2024-02-01",
    )
    return client, azure_deployment.strip()


def _extract_text_blocks(response: Any) -> List[str]:
    """Flatten the response output into a list of text blocks."""
    text_blocks: List[str] = []
    if getattr(response, "output", None):
        for block in response.output:
            for piece in getattr(block, "content", []):
                if hasattr(piece, "text"):
                    text_blocks.append(piece.text)
    return text_blocks


def request_manual_from_responses(client: Any, model_name: str, responses: Dict[str, str]) -> str:
    """Ask the LLM to proofread and compile the aggregated AI responses into a manual."""
    if not responses:
        return ""

    sorted_items = sorted(responses.items(), key=lambda item: item[0].lower())
    outline_lines = []
    for idx, (name, text) in enumerate(sorted_items, start=1):
        outline_lines.append(f"[Step {idx}] {name}\n{text.strip() or 'å†…å®¹ãŒç©ºã§ã™ã€‚'}")
    outline = "\n\n".join(outline_lines)

    manual_prompt = (
        "ã‚ãªãŸã¯æ‰‹é †æ›¸ã‚’ã‚ã‹ã‚Šã‚„ã™ãæ•´ãˆã‚‹ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚"
        "ä»¥ä¸‹ã®ç´ æã¯ç”»åƒè§£æAIãŒç”Ÿæˆã—ãŸä¸‹æ›¸ããªã®ã§ã€èª¤å­—è„±å­—ã‚’æ­£ã—ã€"
        "æ‰‹é †ãŒè¿½ã„ã‚„ã™ã„ã‚ˆã†ã«ã€è¦‹å‡ºã—ã‚„ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’ä»˜ã‘ã¦æ—¥æœ¬èªã§ãƒãƒ‹ãƒ¥ã‚¢ãƒ«åŒ–ã—ã¦ãã ã•ã„ã€‚"
        "å¿…è¦ã«å¿œã˜ã¦æ³¨æ„ç‚¹ã‚„ã‚³ãƒ„ã‚‚è¿½è¨˜ã—ã¦ãã ã•ã„ã€‚\n\n"
        "ç´ æ:\n"
        f"{outline}"
    )

    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": manual_prompt,
                        }
                    ],
                }
            ],
        )
        logging.info("Manual creation response:\n%s", response.model_dump_json(indent=2))
    except Exception as exc:  # pragma: no cover - surface API errors to UI
        st.error(f"ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç”Ÿæˆã®AIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        raise

    text_blocks = _extract_text_blocks(response)
    return text_blocks[0].strip() if text_blocks else ""


def describe_image(client: Any, model_name: str, file_name: str, image_bytes: bytes) -> Dict[str, Any]:
    """Send the image to the selected provider and return both description and raw blocks."""
    base64_image = base64.b64encode(image_bytes).decode("utf-8")
    try:
        response = client.responses.create(
            model=model_name,
            input=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": (
                                "The user is creating a procedural manual. "
                                "Describe the key action, tools, and context shown in this image. "
                                "Write clear, imperative steps in Japanese."
                            ),
                        },
                        {
                            "type": "input_image",
                            "image_url": f"data:image/png;base64,{base64_image}",
                        },
                    ],
                }
            ],
        )
        logging.info(
            "OpenAI raw response for %s:\n%s",
            file_name,
            response.model_dump_json(indent=2),
        )
    except Exception as exc:  # pragma: no cover - surfacing errors to UI
        st.error(f"OpenAI API call failed: {exc}")
        raise

    text_blocks = _extract_text_blocks(response)
    primary_text = text_blocks[0].strip() if text_blocks else ""
    return {"text": primary_text, "raw_blocks": text_blocks}


def build_manual_sections(
    files: List["UploadedFile"],
    responses: Dict[str, str],
    saved_assets: Dict[str, Dict[str, str]],
):
    """Prepare consistent metadata for downstream formatting using saved paths."""
    sections = []
    for file in files:
        asset = saved_assets.get(file.name)
        if not asset:
            continue
        asset_path = Path(asset["path"])
        if not asset_path.exists():
            continue
        sections.append(
            {
                "name": file.name,
                "mime": asset["mime"],
                "path": str(asset_path),
                "text": responses.get(file.name, ""),
            }
        )
    return sections


def build_manual_markdown(sections: List[dict]) -> str:
    """Create a Markdown manual containing the AI descriptions and saved image paths."""
    lines: List[str] = [
        "# è‡ªå‹•ç”Ÿæˆãƒãƒ‹ãƒ¥ã‚¢ãƒ«",
        "",
        f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
    ]

    for idx, section in enumerate(sections, start=1):
        lines.append(f"## Step {idx}: {section['name']}")
        lines.append("")
        body = section.get("text") or "èª¬æ˜ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        lines.append(body.strip())
        source_path = section.get("path")
        if source_path:
            lines.append("")
            lines.append(f"- å‚ç…§ç”»åƒ: `{source_path}`")
        lines.append("")

    return "\n".join(lines).strip() + "\n"


def save_json_to_disk(payload: dict) -> str:
    """Persist JSON to a timestamped file and return the path."""
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    path = DATA_DIR / f"manual-{timestamp}.json"
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    return str(path)


def main() -> None:
    _init_state()

    st.title("Create Manual From images")
    st.caption("è¤‡æ•°ç”»åƒã®æ§˜å­ã‚’èª­ã¿å–ã‚Šãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç”Ÿæˆã‚’æ”¯æ´ã—ã¾ã™ã€‚")

    saved_images: Dict[str, Dict[str, str]] = {}

    provider = "OpenAI"
    openai_api_key = ""
    openai_model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o-mini")
    azure_api_key = ""
    azure_endpoint = ""
    azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "")
    azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01")

    with st.sidebar:
        st.header("æ“ä½œãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        uploaded_files = st.file_uploader(
            "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["png", "jpg", "jpeg", "gif", "webp"],
            accept_multiple_files=True,
        )
        saved_images = _ensure_saved_images(uploaded_files or [])
        provider = st.selectbox("ç”ŸæˆAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", ["OpenAI", "Azure OpenAI"])

        if provider == "OpenAI":
            api_key_default = os.getenv("API_KEY") or os.getenv("OPENAI_API_KEY", "")
            openai_api_key = st.text_input(
                "OpenAI API Key",
                value=api_key_default,
                type="password",
                help="ã‚­ãƒ¼ãŒæœªå…¥åŠ›ã®å ´åˆã¯ç’°å¢ƒå¤‰æ•° API_KEY / OPENAI_API_KEY ã‚’å‚ç…§ã—ã¾ã™ã€‚",
            )
            openai_model_name = st.text_input(
                "OpenAI ãƒ¢ãƒ‡ãƒ«å",
                value=openai_model_name,
                help="ä¾‹: gpt-4o-mini / gpt-4.1-mini ãªã©",
            )
        else:
            azure_api_key_default = os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("AZURE_OPENAI_KEY", "")
            azure_api_key = st.text_input(
                "Azure OpenAI API Key",
                value=azure_api_key_default,
                type="password",
                help="ç’°å¢ƒå¤‰æ•° AZURE_OPENAI_API_KEY / AZURE_OPENAI_KEY ã‚’å‚ç…§ã—ã¾ã™ã€‚",
            )
            azure_endpoint = st.text_input(
                "Azure OpenAI Endpoint",
                value=os.getenv("AZURE_OPENAI_ENDPOINT", azure_endpoint),
                help="ä¾‹: https://example-resource.openai.azure.com",
            )
            azure_deployment = st.text_input(
                "Azure ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå",
                value=azure_deployment,
                help="Azure Portalã§è¨­å®šã—ãŸãƒ¢ãƒ‡ãƒ«/ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
            )
            azure_api_version = st.text_input(
                "Azure API Version",
                value=azure_api_version,
                help="ä¾‹: 2024-02-01",
            )

        if st.button("ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆåŒ–", disabled=not uploaded_files):
            client, target_model = _build_client(
                provider,
                openai_api_key,
                openai_model_name,
                azure_api_key,
                azure_endpoint,
                azure_deployment,
                azure_api_version,
            )

            if client is None or not target_model:
                pass
            elif not saved_images:
                st.warning("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                sorted_files = sorted(uploaded_files, key=lambda f: f.name.lower())
                for file in sorted_files:
                    try:
                        asset = saved_images.get(file.name)
                        if not asset:
                            st.warning(f"{file.name} ã®ä¿å­˜æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                            continue
                        asset_path = Path(asset["path"])
                        if not asset_path.exists():
                            st.warning(f"{asset_path} ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                            continue
                        image_bytes = asset_path.read_bytes()
                        result = describe_image(client, target_model, file.name, image_bytes)
                        st.session_state["ai_responses"][file.name] = result["text"]
                        st.session_state["raw_texts"][file.name] = result["raw_blocks"]
                    except Exception:
                        break

        if st.button("ãƒãƒ‹ãƒ¥ã‚¢ãƒ«åŒ–", disabled=not st.session_state["ai_responses"]):
            client, target_model = _build_client(
                provider,
                openai_api_key,
                openai_model_name,
                azure_api_key,
                azure_endpoint,
                azure_deployment,
                azure_api_version,
            )
            if not uploaded_files:
                st.warning("å…ˆã«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            elif not saved_images:
                st.warning("ç”»åƒã®ä¿å­˜ã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚å†åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            elif client is None or not target_model:
                pass
            else:
                sorted_files = sorted(uploaded_files, key=lambda f: f.name.lower())
                sections = build_manual_sections(
                    sorted_files,
                    st.session_state["ai_responses"],
                    saved_images,
                )
                manual_text = ""
                try:
                    manual_text = request_manual_from_responses(client, target_model, st.session_state["ai_responses"])
                except Exception:
                    manual_text = ""

                fallback_markdown = build_manual_markdown(sections)
                final_markdown = manual_text or fallback_markdown
                manual_json = {
                    "generated_at": datetime.now().isoformat(),
                    "steps": sections,
                    "ai_manual_markdown": manual_text,
                }
                st.session_state["ai_manual_response"] = manual_text
                st.session_state["manual_json"] = manual_json
                st.session_state["manual_markdown"] = final_markdown
                st.session_state["saved_json_path"] = save_json_to_disk(manual_json)

                if manual_text:
                    st.success("AIãŒæ ¡æ­£ã¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«åŒ–ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚ä¸‹éƒ¨ã§ã”ç¢ºèªãã ã•ã„ã€‚")
                else:
                    st.warning("AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€å¾“æ¥å½¢å¼ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§å‡ºåŠ›ã—ã¾ã—ãŸã€‚")

    sorted_uploads = sorted(uploaded_files, key=lambda f: f.name.lower()) if uploaded_files else []

    st.subheader("ç”»åƒã¨AIãƒ¬ã‚¹ãƒãƒ³ã‚¹")
    if not sorted_uploads:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        for file in sorted_uploads:
            image = file.read()
            col_img, col_resp = st.columns(2)
            with col_img:
                st.image(image, caption=file.name, use_container_width=True)
            with col_resp:
                st.markdown(f"**{file.name}**")
                response_text = st.session_state["ai_responses"].get(file.name, "").strip()
                st.markdown(response_text or "_çµæœãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚_")
            file.seek(0)
            st.divider()

    st.subheader("AIæ ¡æ­£æ¸ˆã¿ãƒãƒ‹ãƒ¥ã‚¢ãƒ« (Markdown)")
    manual_text = st.session_state.get("manual_markdown", "")
    ai_manual_text = st.session_state.get("ai_manual_response", "").strip()

    if manual_text:
        if ai_manual_text:
            st.caption("AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å…ƒã«æ ¡æ­£ã•ã‚ŒãŸãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§ã™ã€‚")
        else:
            st.caption("AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€å¾“æ¥å½¢å¼ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")

        st.markdown(manual_text)
        st.download_button(
            "ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.md)",
            data=manual_text,
            file_name="manual.md",
            mime="text/markdown",
        )

        if st.session_state["manual_json"]:
            st.download_button(
                "JSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=json.dumps(st.session_state["manual_json"], ensure_ascii=False, indent=2),
                file_name="manual.json",
                mime="application/json",
            )

        if st.session_state["saved_json_path"]:
            st.caption(f"JSONã¯ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚‚ä¿å­˜æ¸ˆã¿: `{st.session_state['saved_json_path']}`")
    else:
        st.info("ã€Œãƒãƒ‹ãƒ¥ã‚¢ãƒ«åŒ–ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")


if __name__ == "__main__":
    main()
